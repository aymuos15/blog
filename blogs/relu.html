<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Understanding ReLU - Machine Learning, Through PyTorch Code</title>
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <nav>
        <a href="../index.html">← Home</a>
    </nav>

    <h1>Understanding ReLU</h1>
    <p class="subtitle">Why Forward and Backward Passes Use Different Code</p>

    <h2>What is ReLU?</h2>
    <p>ReLU (Rectified Linear Unit) is a simple activation function used in neural networks. If the input is <strong>positive</strong>, keep it. If <strong>negative or zero</strong>, output 0.</p>
    <div class="highlight-box">
        <strong>Mathematical definition:</strong> ReLU(x) = max(0, x)
    </div>

    <canvas id="reluGraph" width="700" height="300" style="width: 100%; height: auto; border: 1px solid #000; margin: 30px 0;"></canvas>

<div class="visual-demo">
    <h3 style="text-align: center; margin-bottom: 20px;">Interactive ReLU Graph</h3>
    <p style="text-align: center; color: #666; margin-bottom: 30px;">Move the slider to see how different input values are transformed by ReLU</p>
    <canvas id="reluGraphDynamic" width="700" height="300" style="width: 100%; height: auto; border: 1px solid #000;"></canvas>
    <div style="margin-top: 20px;">
        <label style="display: block; text-align: center; margin-bottom: 10px;">
            Input value (x): <strong id="xValue">0</strong>
        </label>
        <input type="range" id="xSlider" min="-5" max="5" step="0.1" value="0"
               style="width: 100%; cursor: pointer;">
        <div style="display: flex; justify-content: space-between; margin-top: 10px; font-size: 0.9em; color: #666;">
            <span>-5</span>
            <span>Output: <strong id="yValue" style="color: #2563eb;">0</strong></span>
            <span>5</span>
        </div>
    </div>
</div>

    <h2>The Forward Pass</h2>
    <p>The forward pass computes the <strong>actual ReLU function</strong>:</p>
    <div class="code-tabs">
        <div class="tab-buttons">
            <button class="tab-button active" onclick="switchTab(event, 'forward-simple')">Simple</button>
            <button class="tab-button" onclick="switchTab(event, 'forward-optimized')">Optimized</button>
        </div>
        <div id="forward-simple" class="tab-content active">
            <div class="code-block"><span class="keyword">def</span> <span class="function">forward</span>(ctx, x):
    <span class="comment"># Save input for backward pass</span>
    ctx.save_for_backward(x)

    <span class="comment"># Return max of x and zeros</span>
    <span class="keyword">return</span> torch.max(x, torch.zeros_like(x))</div>
        </div>
        <div id="forward-optimized" class="tab-content">
            <div class="code-block"><span class="keyword">def</span> <span class="function">forward</span>(ctx, x):
    <span class="comment"># Save input for backward pass</span>
    ctx.save_for_backward(x)

    <span class="comment"># More efficient: clamp avoids creating zero tensor</span>
    <span class="keyword">return</span> x.clamp(min=<span class="number">0</span>)</div>
        </div>
    </div>

    <div class="visual-explanation">
        <div class="column">
            <h3>Input</h3>
            <div>[-2, 0, 3]</div>
        </div>
        <div class="arrow">→</div>
        <div class="column">
            <h3>Apply ReLU</h3>
            <div>max(0, x)</div>
        </div>
        <div class="arrow">→</div>
        <div class="column">
            <h3>Output</h3>
            <div>[0, 0, 3]</div>
        </div>
    </div>

    <div class="visual-demo">
        <h3 style="text-align: center; margin-bottom: 20px;">Forward Pass Visualization</h3>
        <p style="text-align: center; color: #666; margin-bottom: 30px;">Watch how ReLU transforms each element</p>
        <div class="matrix-container" id="forwardViz">
            <div class="matrix">
                <div class="matrix-label">Input</div>
                <div class="matrix-grid" id="forwardInput" style="grid-template-columns: repeat(3, 1fr);"></div>
            </div>
            <div class="operation">→</div>
            <div class="matrix">
                <div class="matrix-label">ReLU</div>
                <div class="matrix-grid" id="forwardOperation" style="grid-template-columns: repeat(3, 1fr);"></div>
            </div>
            <div class="operation">→</div>
            <div class="matrix">
                <div class="matrix-label">Output</div>
                <div class="matrix-grid" id="forwardOutput" style="grid-template-columns: repeat(3, 1fr);"></div>
            </div>
        </div>
        <div class="control-buttons">
            <button onclick="animateForward()">Animate Forward Pass</button>
            <button onclick="resetForward()">Reset</button>
        </div>
    </div>

    <h2>The Backward Pass</h2>
    <p>The backward pass computes the <strong>derivative (gradient)</strong> of ReLU:</p>
    <div class="code-tabs">
        <div class="tab-buttons">
            <button class="tab-button active" onclick="switchTab(event, 'backward-simple')">Simple</button>
            <button class="tab-button" onclick="switchTab(event, 'backward-optimized')">Optimized</button>
        </div>
        <div id="backward-simple" class="tab-content active">
            <div class="code-block"><span class="keyword">def</span> <span class="function">backward</span>(ctx, grad_output):
    <span class="comment"># Retrieve saved input</span>
    input_x, = ctx.saved_tensors

    <span class="comment"># Clone gradient to avoid modifying original</span>
    grad_input = grad_output.clone()

    <span class="comment"># Set gradient to 1 where x > 0</span>
    grad_input[input_x > <span class="number">0</span>] *= <span class="number">1</span>

    <span class="comment"># Set gradient to 0 where x <= 0</span>
    grad_input[input_x <= <span class="number">0</span>] *= <span class="number">0</span>

    <span class="keyword">return</span> grad_input</div>
        </div>
        <div id="backward-optimized" class="tab-content">
            <div class="code-block"><span class="keyword">def</span> <span class="function">backward</span>(ctx, grad_output):
    <span class="comment"># Retrieve saved input</span>
    input_x, = ctx.saved_tensors

    <span class="comment"># More efficient: directly multiply by boolean mask</span>
    <span class="keyword">return</span> grad_output * (input_x > <span class="number">0</span>)</div>
        </div>
    </div>

    <div class="highlight-box">
        <strong>The derivative tells us how much the output changes when we change the input.</strong><br><br>
        Derivative of ReLU:<br>
        If x > 0: derivative = <strong>1</strong> (slope is 1)<br>
        If x ≤ 0: derivative = <strong>0</strong> (flat, no change)
    </div>

    <div class="visual-explanation">
        <div class="column">
            <h3>Gradient In</h3>
            <div>[1, 1, 1]</div>
        </div>
        <div class="arrow">→</div>
        <div class="column">
            <h3>Derivative Mask</h3>
            <div>(x > 0)<br>[0, 0, 1]</div>
        </div>
        <div class="arrow">→</div>
        <div class="column">
            <h3>Gradient Out</h3>
            <div>[0, 0, 1]</div>
        </div>
    </div>

    <div class="visual-demo">
        <h3 style="text-align: center; margin-bottom: 20px;">Backward Pass Visualization</h3>
        <p style="text-align: center; color: #666; margin-bottom: 30px;">Watch how gradients flow through the derivative mask</p>
        <div class="matrix-container" id="backwardViz">
            <div class="matrix">
                <div class="matrix-label">Gradient In</div>
                <div class="matrix-grid" id="backwardGradIn" style="grid-template-columns: repeat(3, 1fr);"></div>
            </div>
            <div class="operation">×</div>
            <div class="matrix">
                <div class="matrix-label">Derivative Mask</div>
                <div class="matrix-grid" id="backwardMask" style="grid-template-columns: repeat(3, 1fr);"></div>
            </div>
            <div class="operation">=</div>
            <div class="matrix">
                <div class="matrix-label">Gradient Out</div>
                <div class="matrix-grid" id="backwardGradOut" style="grid-template-columns: repeat(3, 1fr);"></div>
            </div>
        </div>
        <div class="control-buttons">
            <button onclick="animateBackward()">Animate Backward Pass</button>
            <button onclick="resetBackward()">Reset</button>
        </div>
    </div>

    <h2>Why They're Different</h2>
    <p><strong>Forward</strong> transforms the <strong>data</strong> by applying the ReLU function.</p>
    <p><strong>Backward</strong> transforms the <strong>gradients</strong> by applying the ReLU derivative.</p>

    <div class="highlight-box">
        <strong>Example with x = -2:</strong><br>
        Forward: ReLU(-2) = 0 (the function value)<br>
        Backward: derivative = 0 (because the function is flat when x < 0)
    </div>

    <h2>Interactive Demo</h2>
    <div class="interactive-demo">
        <p style="text-align: center; margin-bottom: 30px;">Enter values to see the forward and backward passes in action</p>

        <div class="input-group">
            <label>Input Values (x)</label>
            <input type="text" id="inputValues" value="-2, 0, 3">
        </div>
        <div class="input-group">
            <label>Gradient from Above (∂L/∂y)</label>
            <input type="text" id="gradValues" value="1, 1, 1">
        </div>
        <button onclick="compute()">Compute</button>

        <div id="results"></div>
    </div>

    <h2>Summary</h2>
    <div class="highlight-box">
        Forward and backward passes use different code because they compute <strong>different mathematical operations</strong>.<br><br>
        <strong>Forward</strong> computes the function ReLU(x).<br>
        <strong>Backward</strong> computes the derivative of ReLU.<br><br>
        They are related but <strong>mathematically distinct</strong>.
    </div>

    <footer>
        A minimal explanation of neural network backpropagation
    </footer>

    <script>
        // Data for visualizations
        const inputData = [-2, 0, 3];
        const forwardOutputData = [0, 0, 3];
        const gradInData = [1, 1, 1];
        const maskData = [0, 0, 1];
        const gradOutData = [0, 0, 1];

        let forwardAnimating = false;
        let backwardAnimating = false;

        function createMatrix(elementId, data) {
            const container = document.getElementById(elementId);
            if (!container) return;
            container.innerHTML = '';
            data.forEach((value, index) => {
                const cell = document.createElement('div');
                cell.className = 'matrix-cell';
                cell.textContent = value;
                cell.id = `${elementId}-${index}`;
                container.appendChild(cell);
            });
        }

        function initializeVisualizations() {
            // Forward pass
            createMatrix('forwardInput', inputData);
            createMatrix('forwardOperation', ['?', '?', '?']);
            createMatrix('forwardOutput', ['?', '?', '?']);

            // Backward pass
            createMatrix('backwardGradIn', gradInData);
            createMatrix('backwardMask', maskData);
            createMatrix('backwardGradOut', ['?', '?', '?']);
        }

        async function animateForward() {
            if (forwardAnimating) return;
            forwardAnimating = true;

            // Reset
            createMatrix('forwardOperation', ['?', '?', '?']);
            createMatrix('forwardOutput', ['?', '?', '?']);

            for (let i = 0; i < inputData.length; i++) {
                // Highlight input
                const inputCell = document.getElementById(`forwardInput-${i}`);
                inputCell.classList.add('highlight');

                await sleep(500);

                // Show operation (max(0, x))
                const opCell = document.getElementById(`forwardOperation-${i}`);
                opCell.textContent = `max(0,${inputData[i]})`;
                opCell.classList.add('processing');

                await sleep(700);

                // Show output
                const outputCell = document.getElementById(`forwardOutput-${i}`);
                outputCell.textContent = forwardOutputData[i];
                outputCell.classList.add('highlight');

                await sleep(500);

                // Remove highlights
                inputCell.classList.remove('highlight');
                opCell.classList.remove('processing');
                outputCell.classList.remove('highlight');

                await sleep(300);
            }

            forwardAnimating = false;
        }

        function resetForward() {
            createMatrix('forwardInput', inputData);
            createMatrix('forwardOperation', ['?', '?', '?']);
            createMatrix('forwardOutput', ['?', '?', '?']);
            forwardAnimating = false;
        }

        async function animateBackward() {
            if (backwardAnimating) return;
            backwardAnimating = true;

            // Reset
            createMatrix('backwardGradOut', ['?', '?', '?']);

            for (let i = 0; i < gradInData.length; i++) {
                // Highlight gradient in
                const gradInCell = document.getElementById(`backwardGradIn-${i}`);
                gradInCell.classList.add('highlight');

                await sleep(500);

                // Highlight mask
                const maskCell = document.getElementById(`backwardMask-${i}`);
                maskCell.classList.add('processing');

                await sleep(700);

                // Show result (grad_in * mask)
                const gradOutCell = document.getElementById(`backwardGradOut-${i}`);
                gradOutCell.textContent = `${gradInData[i]}×${maskData[i]}=${gradOutData[i]}`;
                gradOutCell.classList.add('highlight');

                await sleep(800);

                // Simplify to final value
                gradOutCell.textContent = gradOutData[i];

                await sleep(500);

                // Remove highlights
                gradInCell.classList.remove('highlight');
                maskCell.classList.remove('processing');
                gradOutCell.classList.remove('highlight');

                await sleep(300);
            }

            backwardAnimating = false;
        }

        function resetBackward() {
            createMatrix('backwardGradIn', gradInData);
            createMatrix('backwardMask', maskData);
            createMatrix('backwardGradOut', ['?', '?', '?']);
            backwardAnimating = false;
        }

        function sleep(ms) {
            return new Promise(resolve => setTimeout(resolve, ms));
        }

        function switchTab(event, tabId) {
            // Get the parent code-tabs container
            const tabsContainer = event.target.closest('.code-tabs');

            // Hide all tab contents in this container
            const tabContents = tabsContainer.querySelectorAll('.tab-content');
            tabContents.forEach(content => {
                content.classList.remove('active');
            });

            // Remove active class from all buttons in this container
            const tabButtons = tabsContainer.querySelectorAll('.tab-button');
            tabButtons.forEach(button => {
                button.classList.remove('active');
            });

            // Show the selected tab content
            document.getElementById(tabId).classList.add('active');

            // Add active class to the clicked button
            event.target.classList.add('active');
        }

        function drawReluGraph() {
            const canvas = document.getElementById('reluGraph');
            if (!canvas) return;

            const ctx = canvas.getContext('2d');
            const width = canvas.width;
            const height = canvas.height;

            // Clear canvas
            ctx.fillStyle = '#fff';
            ctx.fillRect(0, 0, width, height);

            // Set up coordinate system
            const centerX = width / 2;
            const centerY = height / 2;
            const scale = 40;

            // Draw axes
            ctx.strokeStyle = '#999';
            ctx.lineWidth = 1.5;

            // X-axis
            ctx.beginPath();
            ctx.moveTo(0, centerY);
            ctx.lineTo(width, centerY);
            ctx.stroke();

            // Y-axis
            ctx.beginPath();
            ctx.moveTo(centerX, 0);
            ctx.lineTo(centerX, height);
            ctx.stroke();

            // Draw axis labels
            ctx.fillStyle = '#666';
            ctx.font = '14px Georgia';
            ctx.fillText('x', width - 20, centerY - 10);
            ctx.fillText('y', centerX + 10, 20);
            ctx.fillText('0', centerX + 5, centerY - 5);

            // Draw tick marks and labels
            ctx.font = '12px Georgia';
            ctx.strokeStyle = '#ccc';
            ctx.lineWidth = 1;
            for (let i = -5; i <= 5; i++) {
                if (i === 0) continue;

                // X-axis ticks
                const x = centerX + i * scale;
                ctx.beginPath();
                ctx.moveTo(x, centerY - 5);
                ctx.lineTo(x, centerY + 5);
                ctx.stroke();
                ctx.fillStyle = '#666';
                ctx.fillText(i.toString(), x - 5, centerY + 20);

                // Y-axis ticks
                const y = centerY - i * scale;
                ctx.beginPath();
                ctx.moveTo(centerX - 5, y);
                ctx.lineTo(centerX + 5, y);
                ctx.stroke();
                ctx.fillStyle = '#666';
                ctx.fillText(i.toString(), centerX - 25, y + 5);
            }

            // Draw ReLU function in blue
            ctx.strokeStyle = '#2563eb';
            ctx.lineWidth = 3;
            ctx.beginPath();

            // Left part (y = 0 for x < 0)
            ctx.moveTo(0, centerY);
            ctx.lineTo(centerX, centerY);

            // Right part (y = x for x > 0)
            ctx.lineTo(width, centerY - (width - centerX) / scale * scale);

            ctx.stroke();

            // Add label
            ctx.fillStyle = '#2563eb';
            ctx.font = 'bold 16px Georgia';
            ctx.fillText('ReLU(x)', centerX + 100, centerY - 80);
        }

        function drawDynamicReluGraph(xInput) {
            const canvas = document.getElementById('reluGraphDynamic');
            if (!canvas) return;

            const ctx = canvas.getContext('2d');
            const width = canvas.width;
            const height = canvas.height;

            // Clear canvas
            ctx.fillStyle = '#fff';
            ctx.fillRect(0, 0, width, height);

            // Set up coordinate system
            const centerX = width / 2;
            const centerY = height / 2;
            const scale = 40;

            // Draw axes
            ctx.strokeStyle = '#999';
            ctx.lineWidth = 1.5;

            // X-axis
            ctx.beginPath();
            ctx.moveTo(0, centerY);
            ctx.lineTo(width, centerY);
            ctx.stroke();

            // Y-axis
            ctx.beginPath();
            ctx.moveTo(centerX, 0);
            ctx.lineTo(centerX, height);
            ctx.stroke();

            // Draw axis labels
            ctx.fillStyle = '#666';
            ctx.font = '14px Georgia';
            ctx.fillText('x', width - 20, centerY - 10);
            ctx.fillText('y', centerX + 10, 20);
            ctx.fillText('0', centerX + 5, centerY - 5);

            // Draw tick marks and labels
            ctx.font = '12px Georgia';
            ctx.strokeStyle = '#ccc';
            ctx.lineWidth = 1;
            for (let i = -5; i <= 5; i++) {
                if (i === 0) continue;

                // X-axis ticks
                const x = centerX + i * scale;
                ctx.beginPath();
                ctx.moveTo(x, centerY - 5);
                ctx.lineTo(x, centerY + 5);
                ctx.stroke();
                ctx.fillStyle = '#666';
                ctx.fillText(i.toString(), x - 5, centerY + 20);

                // Y-axis ticks
                const y = centerY - i * scale;
                ctx.beginPath();
                ctx.moveTo(centerX - 5, y);
                ctx.lineTo(centerX + 5, y);
                ctx.stroke();
                ctx.fillStyle = '#666';
                ctx.fillText(i.toString(), centerX - 25, y + 5);
            }

            // Draw ReLU function in lighter blue
            ctx.strokeStyle = '#93c5fd';
            ctx.lineWidth = 2;
            ctx.beginPath();

            // Left part (y = 0 for x < 0)
            ctx.moveTo(0, centerY);
            ctx.lineTo(centerX, centerY);

            // Right part (y = x for x > 0)
            ctx.lineTo(width, centerY - (width - centerX) / scale * scale);

            ctx.stroke();

            // Calculate output
            const yOutput = Math.max(0, xInput);

            // Convert to canvas coordinates
            const xPos = centerX + xInput * scale;
            const yPos = centerY - yOutput * scale;

            // Draw vertical line from x-axis to point
            ctx.strokeStyle = '#fbbf24';
            ctx.lineWidth = 2;
            ctx.setLineDash([5, 5]);
            ctx.beginPath();
            ctx.moveTo(xPos, centerY);
            ctx.lineTo(xPos, yPos);
            ctx.stroke();

            // Draw horizontal line from y-axis to point
            ctx.beginPath();
            ctx.moveTo(centerX, yPos);
            ctx.lineTo(xPos, yPos);
            ctx.stroke();
            ctx.setLineDash([]);

            // Draw the point
            ctx.fillStyle = '#2563eb';
            ctx.beginPath();
            ctx.arc(xPos, yPos, 8, 0, 2 * Math.PI);
            ctx.fill();

            // Draw point on x-axis
            ctx.fillStyle = '#fbbf24';
            ctx.beginPath();
            ctx.arc(xPos, centerY, 6, 0, 2 * Math.PI);
            ctx.fill();

            // Draw point on y-axis
            ctx.beginPath();
            ctx.arc(centerX, yPos, 6, 0, 2 * Math.PI);
            ctx.fill();

            // Add labels for the point
            ctx.fillStyle = '#2563eb';
            ctx.font = 'bold 14px Georgia';
            ctx.fillText(`(${xInput.toFixed(1)}, ${yOutput.toFixed(1)})`, xPos + 15, yPos - 10);
        }

        function updateDynamicGraph() {
            const slider = document.getElementById('xSlider');
            const xValue = parseFloat(slider.value);
            const yValue = Math.max(0, xValue);

            document.getElementById('xValue').textContent = xValue.toFixed(1);
            document.getElementById('yValue').textContent = yValue.toFixed(1);

            drawDynamicReluGraph(xValue);
        }

        function initializeDynamicGraph() {
            const slider = document.getElementById('xSlider');
            if (slider) {
                slider.addEventListener('input', updateDynamicGraph);
                updateDynamicGraph();
            }
        }

        function compute() {
            const inputStr = document.getElementById('inputValues').value;
            const gradStr = document.getElementById('gradValues').value;

            const inputs = inputStr.split(',').map(s => parseFloat(s.trim()));
            const grads = gradStr.split(',').map(s => parseFloat(s.trim()));

            if (inputs.some(isNaN) || grads.some(isNaN)) {
                document.getElementById('results').innerHTML =
                    '<div class="result-section"><h3>Error</h3><p>Please enter valid numbers</p></div>';
                return;
            }

            if (inputs.length !== grads.length) {
                document.getElementById('results').innerHTML =
                    '<div class="result-section"><h3>Error</h3><p>Input and gradient arrays must have the same length</p></div>';
                return;
            }

            const forward = inputs.map(x => Math.max(0, x));
            const backward = grads.map((g, i) => inputs[i] > 0 ? g : 0);

            let html = '<div class="result-section">';

            // Forward Pass Section
            html += '<h3>Forward Pass: y = ReLU(x) = max(0, x)</h3>';

            // Overall equation
            html += '<div class="math-equation">';
            html += `y = [${forward.join(', ')}]`;
            html += '</div>';

            // Show computation for each element
            for (let i = 0; i < inputs.length; i++) {
                html += '<div class="element-computation">';
                html += `<div class="step-label">Element ${i + 1}:</div>`;
                html += '<div class="computation-row">';
                html += `<div class="computation-box input">x[${i}] = ${inputs[i]}</div>`;
                html += '<div class="operator">→</div>';
                html += `<div class="computation-box">max(0, ${inputs[i]})</div>`;
                html += '<div class="operator">=</div>';
                html += `<div class="computation-box output">y[${i}] = ${forward[i]}</div>`;
                html += '</div>';
                html += '</div>';
            }

            html += '</div>';

            // Backward Pass Section
            html += '<div class="result-section" style="margin-top: 20px;">';
            html += '<h3>Backward Pass: ∂L/∂x = ∂L/∂y · (x > 0)</h3>';

            // Overall equation
            html += '<div class="math-equation">';
            html += `∂L/∂x = [${backward.join(', ')}]`;
            html += '</div>';

            // Show computation for each element
            for (let i = 0; i < inputs.length; i++) {
                const derivative = inputs[i] > 0 ? 1 : 0;
                html += '<div class="element-computation backward">';
                html += `<div class="step-label">Element ${i + 1}:</div>`;

                html += '<div class="computation-row">';
                html += `<div class="computation-box gradient">∂L/∂y[${i}] = ${grads[i]}</div>`;
                html += '<div class="operator">×</div>';
                html += `<div class="computation-box">(${inputs[i]} > 0) = ${derivative}</div>`;
                html += '<div class="operator">=</div>';
                html += `<div class="computation-box gradient">∂L/∂x[${i}] = ${backward[i]}</div>`;
                html += '</div>';

                html += '<div class="step" style="margin-top: 10px; color: #666;">';
                if (inputs[i] > 0) {
                    html += `Since x[${i}] = ${inputs[i]} > 0, gradient flows through: ${grads[i]} × 1 = ${backward[i]}`;
                } else {
                    html += `Since x[${i}] = ${inputs[i]} ≤ 0, gradient is blocked: ${grads[i]} × 0 = ${backward[i]}`;
                }
                html += '</div>';

                html += '</div>';
            }

            html += '</div>';

            document.getElementById('results').innerHTML = html;
        }

        window.onload = function() {
            drawReluGraph();
            initializeVisualizations();
            initializeDynamicGraph();
            compute();
        };
    </script>
</body>
</html>
