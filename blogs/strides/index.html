<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Understanding Strides - Machine Learning, Through PyTorch Code</title>
    <link rel="stylesheet" href="../../styles.css">
    <link rel="stylesheet" href="strides.css">
    <script src="strides.js" defer></script>
</head>
<body>
    <nav>
        <a href="../../index.html">← Home</a>
    </nav>

    <h1>Understanding Strides</h1>
    <p class="subtitle">and how PyTorch represents multidimensional tensors in contiguous memory.</p>

    <h2>What Are Strides?</h2>
    <p>Strides define how many <strong>bytes</strong> to skip in memory to move to the next element along each dimension. This allows PyTorch to represent different tensor shapes and views using the same underlying data.</p>

    <div class="highlight-box">
        <strong>Key Concept:</strong> A tensor's strides determine the memory layout. PyTorch automatically calculates strides based on the tensor's shape.
    </div>

    <h2>Memory Layout Visualization</h2>
    <p>Let's see how a 2D tensor is actually stored in memory:</p>

    <div class="visual-demo">
        <h3 style="text-align: center; margin-bottom: 20px;">From Shape to Memory</h3>
        <p style="text-align: center; color: #666; margin-bottom: 30px;">Watch how a 2D tensor gets laid out in 1D memory</p>

        <div class="memory-container">
            <div class="tensor-view">
                <div class="view-label">2D View (Shape: 3×3)</div>
                <div class="tensor-grid" id="tensor2D"></div>
            </div>

            <div class="arrow-down">↓</div>

            <div class="memory-view">
                <div class="view-label">Memory Layout (1D Array)</div>
                <div class="memory-blocks" id="memoryBlocks"></div>
            </div>
        </div>

        <div class="stride-info" id="strideInfo">
            <strong>Strides:</strong> <span id="strideValues">(??, ??)</span><br>
            <small>Bytes to skip to move to next [row, column]</small>
        </div>

        <div class="control-buttons">
            <button onclick="animateMemoryLayout()">Show Memory Layout</button>
            <button onclick="animateStrideAccess()">Demonstrate Stride Access</button>
            <button onclick="resetStrides()">Reset</button>
        </div>
    </div>

    <h2>Automatic Stride Calculation</h2>
    <p>PyTorch automatically calculates strides when you create a tensor:</p>

    <div class="code-block"><span class="keyword">import</span> torch

<span class="comment"># Create a 3x3 tensor</span>
x = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],
                  [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],
                  [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])

<span class="keyword">print</span>(x.shape)    <span class="comment"># torch.Size([3, 3])</span>
<span class="keyword">print</span>(x.stride())  <span class="comment"># (3, 1)</span>

<span class="comment"># Stride (3, 1) means:</span>
<span class="comment"># - Move 3 elements to get to next row</span>
<span class="comment"># - Move 1 element to get to next column</span></div>

    <div class="highlight-box">
        <strong>Stride Formula:</strong> For a contiguous tensor, <code>stride[i] = product(shape[i+1:])</code><br><br>
        For shape (3, 3): <code>stride[0] = 3×1 = 3</code>, <code>stride[1] = 1</code>
    </div>

    <h2>Summary</h2>
    <div class="highlight-box">
        <strong>Strides</strong> tell PyTorch how to navigate memory to access tensor elements.<br><br>
        They enable <strong>efficient views</strong> without copying data (like transpose, slicing).<br><br>
        Understanding strides helps you optimize memory usage and performance.
    </div>

    <footer>
        A minimal explanation of neural network backpropagation
    </footer>
</body>
</html>
